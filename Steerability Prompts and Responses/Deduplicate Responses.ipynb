{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc1b182",
   "metadata": {},
   "source": [
    "Script to extract 4 words from responses. While participants were asked to provide 4 words, sometimes they also provided a description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded1dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"Your Key Here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85c7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113309e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"path_to_csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a9d44eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deduplicate_prompt(sentence, response):\n",
    "    prompt = f\"\"\"You are scoring a response from a large language model that is simulating a person.\n",
    "However, the model is not very well trained and the response may be garbled or repeat sections.\n",
    "Your job is to extract the portion of the modelâ€™s response that seems to be relevant and ignore exact repetitions.\n",
    "If the response contains rephrasings of the same idea, keep both rephrasings.\n",
    "Keep as much of the initial response as possible.\n",
    "In some cases, the model may complete the sentence, then generate one or more additional prompt(s) and completion(s).\n",
    "Do not include the additional prompt(s) or completion(s).\n",
    "The model was asked to complete the following sentence: {sentence}\n",
    "The model responded: {response}\n",
    "Please respond only with the pared down version of the model response.\n",
    "\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba473ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [create_deduplicate_prompt(df['sentence'][i], df['response'][i]) for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f5e6cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity Check\n",
    "responses = []\n",
    "for i in range(5):\n",
    "    completion = client.chat.completions.create(model=\"gpt-4o-mini\",\n",
    "              messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an evaluator helping to evaluate language model outputs.\"},\n",
    "                {\"role\": \"user\", \"content\": prompts[i]}])\n",
    "    response =completion.choices[0].message.content.strip()\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fd9af06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.16 s\n",
      "Wall time: 11min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "folder = \"./path/to/file/\"\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith('end_of_file.csv'):\n",
    "        #if\"gemma-2-9b\" not in file: #Gemma-2-9b failed for us, so we don't want to pay openAI to evaluate null responses \n",
    "        if True:\n",
    "            df = pd.read_csv(folder+file)\n",
    "            prompts = []\n",
    "            responses = []\n",
    "            for i in range(len(df)):\n",
    "                prompt = create_pp_prompt(df['prompt'][i],df['response'][i])\n",
    "                prompts.append(prompt)\n",
    "                completion = client.chat.completions.create(model=\"gpt-4o\",\n",
    "                          messages=[\n",
    "                            {\"role\": \"system\", \"content\": \"You are an evaluator helping to evaluate language model outputs.\"},\n",
    "                            {\"role\": \"user\", \"content\": prompts[i]}])\n",
    "                response =completion.choices[0].message.content.strip()\n",
    "                responses.append(response)\n",
    "            new_df = pd.DataFrame(responses, columns =['refusal', 'word1', 'word2', 'word3', 'word4']) \n",
    "            df_combined = pd.concat([df, new_df], axis=1)\n",
    "            new_df.to_csv(folder+'deduplicated/'+file, index=False)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
